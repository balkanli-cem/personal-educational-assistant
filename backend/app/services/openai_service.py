import os
import json
from typing import Dict, List, Any, Optional
from openai import AsyncAzureOpenAI
from dotenv import load_dotenv

load_dotenv()

class OpenAIService:
    def __init__(self):
        # Get API key from environment
        api_key = os.getenv("AZURE_OPENAI_API_KEY") or os.getenv("OPENAI_API_KEY")
        endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
        
        # Check if we have valid credentials for production
        if not api_key or not endpoint or api_key == "dummy-key-for-testing":
            # For testing or when no API key is provided
            self.client = None
            self.enabled = False
            self.deployment_name = "test-model"
        else:
            # Initialize with real API key
            self.client = AsyncAzureOpenAI(
                azure_endpoint=endpoint,
                api_key=api_key,
                api_version=os.getenv("AZURE_OPENAI_API_VERSION", "2024-12-01-preview")
            )
            self.deployment_name = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME", "gpt-4o-mini")
            self.enabled = True
    
    async def generate_explanation(
        self, 
        topic: str, 
        user_input: str, 
        learning_style: str = "visual",
        difficulty_level: str = "beginner",
        explanation_length: str = "medium"
    ) -> str:
        """Generate a personalized explanation"""
        if not self.enabled:
            return f"""**Test Explanation for: {topic}**

**Your Question:** {user_input}

This is a test explanation that would normally be generated by AI. In a real scenario, this would be personalized based on your learning style ({learning_style}) and difficulty level ({difficulty_level}).

**Key Points:**
- This is a placeholder explanation for testing purposes
- The actual AI service would provide detailed, personalized content
- Learning style: {learning_style}
- Difficulty level: {difficulty_level}
- Length: {explanation_length}

**Note:** This explanation is generated in test mode. Connect your OpenAI API key for real AI-powered explanations."""

        try:
            prompt = f"""
You are an expert educational tutor. Create a personalized explanation based on the user's profile.

Topic: {topic}
User Question: {user_input}
Learning Style: {learning_style}
Difficulty Level: {difficulty_level}
Explanation Length: {explanation_length}

Create an engaging, personalized explanation that:
1. Matches the user's learning style
2. Is appropriate for their difficulty level
3. Answers their specific question
4. Uses examples and analogies when helpful
5. Encourages further learning

Format your response as a clear, well-structured explanation.
"""
            
            response = await self.client.chat.completions.create(
                model=self.deployment_name,
                messages=[
                    {"role": "system", "content": "You are an expert educational tutor."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=1000
            )
            
            return response.choices[0].message.content.strip()
        except Exception as e:
            return f"Error generating explanation: {str(e)}"
    
    async def generate_quiz(
        self, 
        topic: str, 
        difficulty_level: str = "beginner",
        num_questions: int = 5
    ) -> List[Dict[str, Any]]:
        """Generate quiz questions for a topic"""
        if not self.enabled:
            # Return test quiz questions
            test_questions = []
            for i in range(num_questions):
                test_questions.append({
                    "question": f"Test question {i+1} about {topic}?",
                    "options": [
                        f"Option A for question {i+1}",
                        f"Option B for question {i+1}",
                        f"Option C for question {i+1}",
                        f"Option D for question {i+1}"
                    ],
                    "correct_answer": 0,
                    "explanation": f"This is a test explanation for question {i+1}. In test mode, the first option is always correct."
                })
            return test_questions

        try:
            prompt = f"""
You are an expert quiz creator. Generate educational quiz questions for the given topic.

Topic: {topic}
Difficulty Level: {difficulty_level}
Number of Questions: {num_questions}

Create {num_questions} multiple-choice questions that:
1. Test understanding of the topic
2. Match the difficulty level
3. Have 4 answer options each
4. Include one correct answer and three plausible distractors
5. Cover different aspects of the topic

Format your response as JSON with this structure:
{{
    "questions": [
        {{
            "question": "Question text here",
            "options": ["Option A", "Option B", "Option C", "Option D"],
            "correct_answer": 0,
            "explanation": "Why this answer is correct"
        }}
    ]
}}
"""
            
            response = await self.client.chat.completions.create(
                model=self.deployment_name,
                messages=[
                    {"role": "system", "content": "You are an expert quiz creator. Always respond with valid JSON."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=2000
            )
            
            content = response.choices[0].message.content.strip()
            quiz_data = json.loads(content)
            return quiz_data.get("questions", [])
        except Exception as e:
            print(f"Quiz generation error: {str(e)}")  # Add logging
            return [{"error": f"Error generating quiz: {str(e)}"}]
    
    async def evaluate_answer(
        self, 
        topic: str, 
        question: str, 
        correct_answer: str, 
        user_response: str
    ) -> str:
        """Evaluate user's answer and provide feedback"""
        if not self.enabled:
            return f"""**Test Feedback for: {topic}**

**Question:** {question}
**Your Answer:** {user_response}
**Correct Answer:** {correct_answer}

This is test feedback that would normally be generated by AI. In a real scenario, this would provide:
- Detailed analysis of your answer
- Constructive feedback
- Suggestions for improvement
- Encouragement to continue learning

**Note:** This feedback is generated in test mode. Connect your OpenAI API key for real AI-powered feedback."""

        try:
            prompt = f"""
You are an expert educational evaluator. Provide feedback on the user's answer.

Topic: {topic}
Question: {question}
Correct Answer: {correct_answer}
User's Answer: {user_response}

Provide:
1. Whether the answer is correct or incorrect
2. Constructive feedback explaining why
3. Suggestions for improvement if needed
4. Encouragement to continue learning

Be supportive and educational in your feedback.
"""
            
            response = await self.client.chat.completions.create(
                model=self.deployment_name,
                messages=[
                    {"role": "system", "content": "You are an expert educational evaluator."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=500
            )
            
            return response.choices[0].message.content.strip()
        except Exception as e:
            return f"Error evaluating answer: {str(e)}"
    
    async def generate_learning_path(
        self, 
        topic: str, 
        current_level: str = "beginner",
        learning_goals: List[str] = None
    ) -> Dict[str, Any]:
        """Generate a personalized learning path"""
        if not self.enabled:
            # Return test learning path
            return {
                "topic": topic,
                "current_level": current_level,
                "learning_goals": learning_goals or ["general understanding"],
                "modules": [
                    {
                        "title": f"Introduction to {topic}",
                        "description": f"Learn the basics of {topic}",
                        "duration": "2-3 hours",
                        "prerequisites": ["Basic knowledge"],
                        "objectives": [f"Understand {topic} fundamentals"]
                    },
                    {
                        "title": f"Advanced {topic} Concepts",
                        "description": f"Dive deeper into {topic}",
                        "duration": "3-4 hours",
                        "prerequisites": [f"Introduction to {topic}"],
                        "objectives": [f"Master advanced {topic} concepts"]
                    }
                ],
                "total_estimated_time": "5-7 hours"
            }

        try:
            goals_text = ", ".join(learning_goals) if learning_goals else "general understanding"
            
            prompt = f"""
Create a personalized learning path for the topic: {topic}

Current Level: {current_level}
Learning Goals: {goals_text}

Generate a structured learning path with:
1. Learning objectives
2. Step-by-step modules
3. Prerequisites
4. Estimated time for each module
5. Recommended resources

Format as JSON with this structure:
{{
    "topic": "{topic}",
    "current_level": "{current_level}",
    "learning_goals": {learning_goals or []},
    "modules": [
        {{
            "title": "Module title",
            "description": "What you'll learn",
            "duration": "Estimated time",
            "prerequisites": ["Required knowledge"],
            "objectives": ["Learning objectives"]
        }}
    ],
    "total_estimated_time": "Total time estimate"
}}

IMPORTANT: Respond with ONLY valid JSON. No additional text or explanations.
"""
            
            response = await self.client.chat.completions.create(
                model=self.deployment_name,
                messages=[
                    {"role": "system", "content": "You are an expert educational curriculum designer. Always respond with valid JSON only. No additional text."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=2000
            )
            
            content = response.choices[0].message.content.strip()
            
            # Clean up the response to ensure it's valid JSON
            if content.startswith("```json"):
                content = content[7:]
            if content.endswith("```"):
                content = content[:-3]
            
            return json.loads(content)
        except json.JSONDecodeError as e:
            return {
                "error": f"JSON parsing error: {str(e)}",
                "raw_response": content if 'content' in locals() else "No response received"
            }
        except Exception as e:
            return {"error": f"Error generating learning path: {str(e)}"}

# Global instance
openai_service = OpenAIService()